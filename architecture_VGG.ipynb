{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9690c00-a6e0-4f5c-9304-946da6661c13",
   "metadata": {},
   "source": [
    "Architecture simil VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f021b7e-b159-44fa-bcb1-aafe200e41a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 10:35:25.140565: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/enrico/ComputerVision/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import keras\n",
    "import pandas as pd\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "seed = 42 # for testability purposes\n",
    "keras.utils.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863b261b-faee-4ed8-95e9-eedc7dd3db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_to_change(img, size):\n",
    "    if img.shape[0] <= img.shape[1]:\n",
    "        return (256, int(np.floor(256 / img.shape[0] * img.shape[1])))\n",
    "    else:\n",
    "        return (int(np.floor(256 / img.shape[1] * img.shape[0])), 256)\n",
    "\n",
    "def load_data(url_directory, url_file, size=256, crop_dim=224, random_crop=False, central_crop=False, return_original=False):\n",
    "    X = []\n",
    "    y = []\n",
    "    X_original = []\n",
    "    \n",
    "    with open(url_directory + url_file) as f:\n",
    "        for line in f:\n",
    "            line_split = line.split(\",\")\n",
    "            img = cv2.imread(url_directory + line_split[0])\n",
    "            img_resized = cv2.resize(img, size_to_change(img, size))\n",
    "            lbl = int(line_split[2].strip())\n",
    "\n",
    "            if random_crop:\n",
    "                crop = get_random_crop(img_resized, crop_dim, crop_dim) # is it fine even for val and test?\n",
    "            elif central_crop: # center crop\n",
    "                img_center = (img_resized.shape[0] // 2, img_resized.shape[1] // 2)\n",
    "                crop_dim_half = crop_dim // 2\n",
    "                crop = img_resized[\n",
    "                    img_center[0] - crop_dim_half : img_center[0] - crop_dim_half + crop_dim,\n",
    "                    img_center[1] - crop_dim_half : img_center[1] - crop_dim_half + crop_dim\n",
    "                    ]\n",
    "            else:\n",
    "                crop = img_resized[:crop_dim, :crop_dim]\n",
    "\n",
    "            X.append(crop)\n",
    "            y.append(lbl)\n",
    "\n",
    "            if return_original:\n",
    "                img_resized_original = img_resized[:size, :size]\n",
    "                X_original.append(img_resized_original)\n",
    "\n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if return_original:\n",
    "        return X, y, np.stack(X_original, axis=0)\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44222e6d-86f8-4283-87c0-6c588e306d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_directory = \"../GroceryStoreDataset/dataset/\"\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_train, y_train = load_data(url_directory, \"train.txt\")\n",
    "X_val, y_val = load_data(url_directory, \"val.txt\")\n",
    "X_test, y_test = load_data(url_directory, \"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419a8ba-d38b-454a-8732-69e74abfd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = pd.read_csv(url_directory + \"classes.csv\")\n",
    "df_coarse = df_classes.loc[:, ['Coarse Class Name (str)', 'Coarse Class ID (int)']].drop_duplicates().values\n",
    "labels_coarse = {i: lbl for lbl, i in df_coarse}\n",
    "n_classes_coarse = len(labels_coarse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f03fc-c1dc-4a83-a4a8-51985bfa4106",
   "metadata": {},
   "source": [
    "#### MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011d7d5-1f63-4e9e-b177-4c62043e147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Rescaling, RandomColorJitter, RandomCrop, RandomErasing,\\\n",
    "    RandomFlip, RandomRotation, RandomZoom, RandomTranslation, Dropout\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "#crop_dim = 224\n",
    "\n",
    "model = Sequential(\n",
    "    [   \n",
    "        # Input layer.\n",
    "        Input(shape=input_shape),\n",
    "        \n",
    "        # Data Augmentation\n",
    "        #RandomCrop(height=224, width=224),\n",
    "        RandomFlip(mode='horizontal'),\n",
    "        RandomRotation(factor=0.2),\n",
    "        RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "        RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        RandomColorJitter(brightness_factor=(0.8, 1.2), contrast_factor=(0.8, 1.2), saturation_factor=(0.8, 1.2)),\n",
    "        RandomErasing(factor=0.2, fill_value='random'),\n",
    "\n",
    "        # Data Normalisation\n",
    "        Rescaling(1./255),\n",
    "\n",
    "        # Convolutions with subsequent pooling\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # Classification head.\n",
    "        Flatten(),\n",
    "        \n",
    "        Dropout(0.5),\n",
    "        Dense(units=4096, activation='relu'),\n",
    "\n",
    "        Dropout(0.5),\n",
    "        Dense(units=4096, activation='relu'),\n",
    "\n",
    "        Dense(units=n_classes_coarse, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb54bf-75e7-4f37-98e3-c32e9966e8da",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922eb9b-2b1e-4585-8213-2d4367d5ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "opt = Adam(learning_rate = 1e-3)\n",
    "loss_fcn = SparseCategoricalCrossentropy()\n",
    "batch_size = 32 #128\n",
    "epochs = 40 \n",
    "\n",
    "model.compile(\n",
    "    loss = loss_fcn,\n",
    "    optimizer = opt, \n",
    "    metrics = [\"accuracy\"]\n",
    ") \n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs = epochs, \n",
    "    validation_data = (X_val, y_val)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b6c112-db77-45ab-9942-028170919b96",
   "metadata": {},
   "source": [
    "#### MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f4086-387a-4bc5-840b-3c699c99d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 3))\n",
    "for i, metric in enumerate([\"accuracy\", \"loss\"]):\n",
    "    plt.subplot(1, 2, i + 1) \n",
    "    plt.plot(model.history.history[metric])\n",
    "    plt.plot(model.history.history[\"val_\" + metric])\n",
    "    plt.title(\"Model {}\".format(metric))\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train\", \"val\"])\n",
    "\n",
    "val_loss, val_metric = model.evaluate(X_val, y_val, verbose = 1)\n",
    "print(f\"The test loss is {val_loss:.4f}, the test accuracy is {val_metric:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1639447-46f1-46ea-9f77-574fcd5aac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_metric = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(f\"The test loss is {test_loss:.4f}, the test accuracy is {test_metric:.4f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
